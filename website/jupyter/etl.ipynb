{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a5eaad",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load (ETL)\n",
    "---\n",
    "The purpose of this Jupyter Notebook is to extract data and storing it in a SQLite database within this package. The codes below show the steps in this process:\n",
    "- Data pulling ['Starbucks', 'Think Coffee', 'Joe Coffee', 'Gregorys Coffee', 'Birch Coffee']\n",
    "- ETL - for only needed data that will be used to store in the database\n",
    "- Configure database\n",
    "    - Delete (if exists) and create a new database coffee_chains.sqlite and the table\n",
    "    - Load data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3afa587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from api_key import api_key\n",
    "from jsonschema import validate\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac5547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Yelp API constants\n",
    "API_HOST = 'https://api.yelp.com/v3/businesses/search'\n",
    "HEADERS = {\n",
    "    'Authorization': 'bearer %s' % api_key\n",
    "}\n",
    "\n",
    "# Schema for comparing in checking before extraction\n",
    "schema = {\n",
    "    'alias': '',\n",
    "    'categories': [],\n",
    "    'coordinates': {},\n",
    "    'display_phone': '',\n",
    "    'distance': 0.00,\n",
    "    'id': 'string',\n",
    "    'image_url': '',\n",
    "    'is_closed': True,\n",
    "    'location': {},\n",
    "    'name': '',\n",
    "    'phone': '',\n",
    "    'price': '',\n",
    "    'rating': 0.0,\n",
    "    'review_count': 0,\n",
    "    'transaction': [],\n",
    "    'url': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcc1e3",
   "metadata": {},
   "source": [
    "### Custom functions for the ETL steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb2bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple request function for bussiness search endpoint from Yelp API\n",
    "def request(term = '', loc = ''):\n",
    "    data = []\n",
    "    \n",
    "    for offset in range(0, 200, 50):\n",
    "        params = {\n",
    "            'term': term.replace(' ', '+'),\n",
    "            'location': loc.replace(' ', '+'),\n",
    "            'limit': 50,\n",
    "            'offset': offset\n",
    "        }\n",
    "\n",
    "        # Send the request\n",
    "        response = requests.get(API_HOST, headers = HEADERS, params = params)\n",
    "\n",
    "        # Verify the response and return None if error returned else return the json data\n",
    "        if response.status_code == 200:\n",
    "            data += response.json()['businesses']\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function to verify the predefined schema on what we should be expecting before extracting\n",
    "def verify_schema(data = None):\n",
    "    \n",
    "    # Verify the object entered before extraction\n",
    "    if data == None:\n",
    "        return False\n",
    "    elif not isinstance(data, dict):\n",
    "        return False\n",
    "    else:\n",
    "        try:\n",
    "            validate(instance=data, schema=schema)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Return the json to DF for cleanining\n",
    "def json_to_dataframe(data = None):\n",
    "    try:\n",
    "        if not verify_schema(data[0]):\n",
    "            return pd.DataFrame({'error': [\"{'error': 'SCHEMA VALIDATION ERROR'}\"]})\n",
    "        else:\n",
    "            return pd.DataFrame(data)\n",
    "    except TypeError:\n",
    "        return pd.DataFrame({'error': [\"{'error': 'OBJECT INPUT ERROR'}\"]})\n",
    "\n",
    "# Function to extract the id, name, price, rating, review_count, location (address 1, address 2, address 3, city, \n",
    "# state, zip_code), coordinates (latitude and longtitude), and phone into a DataFrame\n",
    "def cleaned_yelp_dataframe(df, name):\n",
    "    # Create a copy of the df to work with\n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    # Sometimes random result return not matching the criteria, filter those out by the name\n",
    "    key_search = [name.lower()]\n",
    "    clean_df['name'] = clean_df.name.apply(lambda x: x.lower())\n",
    "    clean_df = clean_df.loc[clean_df['name'].isin(key_search)]\n",
    "    \n",
    "    # Normalizing the coordinates and location columns with nested dictionary\n",
    "    clean_df[['latitude', 'longitude']] = pd.json_normalize(clean_df['coordinates'])\n",
    "    clean_df[[\n",
    "        'address1', \n",
    "        'address2', \n",
    "        'address3', \n",
    "        'city', \n",
    "        'zip', \n",
    "        'country', \n",
    "        'state', \n",
    "        'display_address'\n",
    "    ]] = pd.json_normalize(clean_df['location'])\n",
    "    \n",
    "    # Drop off the columns no longer needed\n",
    "    clean_df = clean_df.drop(columns = [\n",
    "        'alias', 'image_url', 'is_closed', 'url', 'categories', 'coordinates', 'transactions', 'location',\n",
    "        'phone', 'distance', 'display_address'        \n",
    "    ])\n",
    "    \n",
    "    # Add price point column, fill na, and convert to int\n",
    "    clean_df['price'] = clean_df['price'].fillna('')\n",
    "    clean_df['price_point'] = clean_df['price'].str.len()\n",
    "    clean_df['price_point'] = clean_df['price_point'].fillna(0)\n",
    "    clean_df['price_point'] = clean_df['price_point'].astype('int')\n",
    "    \n",
    "    # Reorganize the df for easy viewing\n",
    "    clean_df = clean_df[[\n",
    "        'id', 'name', 'review_count', 'rating', 'price', 'price_point', 'display_phone', 'address1', 'address2', 'address3',\n",
    "        'city', 'state', 'zip', 'country', 'latitude', 'longitude'\n",
    "    ]]\n",
    "    \n",
    "    # Filter out just stores found within New York or Brooklyn cities\n",
    "    key_search = ['New York', 'Brooklyn']\n",
    "    clean_df = clean_df.loc[clean_df['city'].isin(key_search)]\n",
    "    \n",
    "    # Replace any \"None\" values from address2 and address3 to \"\"\n",
    "    clean_df['address2'] = clean_df['address2'].fillna('')\n",
    "    clean_df['address3'] = clean_df['address3'].fillna('')\n",
    "    \n",
    "    # Proper casing for the name and city\n",
    "    clean_df['name'] = clean_df['name'].str.title()\n",
    "\n",
    "    # Take only rows that do not have nan for coordinates\n",
    "    clean_df = clean_df[clean_df['latitude'].notna()]\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8be0d",
   "metadata": {},
   "source": [
    "### Perform the ETL into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ae1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop to pull the requests, clean, and then combine to export out into one single json file and add to database\n",
    "coffee_chains = ['Starbucks', 'Dunkin\\' Donuts', 'Tim Hortons', 'Think Coffee', 'Joe Coffee', 'Gregorys Coffee', 'Birch Coffee']\n",
    "dfs = []\n",
    "\n",
    "# Loop through to append the output cleaned df of each coffee chain for the merging using the defined functions from above\n",
    "for shop in coffee_chains:\n",
    "    coffee_data = request(shop, 'nyc')\n",
    "    coffee_data = json_to_dataframe(coffee_data)\n",
    "    cleaned_coffee_data = cleaned_yelp_dataframe(coffee_data, shop)\n",
    "    dfs.append(cleaned_coffee_data)\n",
    "\n",
    "# Now perform the merge\n",
    "df_merged = pd.concat(dfs)\n",
    "\n",
    "# Export out into csv and json in addition to adding it to a SQLite database\n",
    "df_merged.to_csv('../static/dataset/merged.csv', index = False)\n",
    "df_merged.to_json('../static/dataset/merged.json', orient = 'records', indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef56d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "      <th>price_point</th>\n",
       "      <th>display_phone</th>\n",
       "      <th>address1</th>\n",
       "      <th>address2</th>\n",
       "      <th>address3</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qcnoyytlFIuqlcjDXkXJiw</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$$</td>\n",
       "      <td>2</td>\n",
       "      <td>(718) 855-0856</td>\n",
       "      <td>67 Main St</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>11201</td>\n",
       "      <td>US</td>\n",
       "      <td>40.702754</td>\n",
       "      <td>-73.990884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60agfQbky4cX8BEApyltIA</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>$</td>\n",
       "      <td>1</td>\n",
       "      <td>(646) 699-9983</td>\n",
       "      <td>375 Pearl St</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10038</td>\n",
       "      <td>US</td>\n",
       "      <td>40.711020</td>\n",
       "      <td>-74.000910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0EKm9V9QI2R47QkRWA5aQ</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$</td>\n",
       "      <td>1</td>\n",
       "      <td>(929) 955-1841</td>\n",
       "      <td>99 Wall St</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10005</td>\n",
       "      <td>US</td>\n",
       "      <td>40.704901</td>\n",
       "      <td>-74.007244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OuNYQaqEJjkBHRdnC-4HOw</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>$$</td>\n",
       "      <td>2</td>\n",
       "      <td>(212) 509-9709</td>\n",
       "      <td>100 William St</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10038</td>\n",
       "      <td>US</td>\n",
       "      <td>40.708413</td>\n",
       "      <td>-74.007387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mEMPhPK6dSgy5eXS-kYHLg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$$</td>\n",
       "      <td>2</td>\n",
       "      <td>(718) 243-0455</td>\n",
       "      <td>134 Montague St</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>11201</td>\n",
       "      <td>US</td>\n",
       "      <td>40.694582</td>\n",
       "      <td>-73.993978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id       name  review_count  rating price  price_point  \\\n",
       "0  qcnoyytlFIuqlcjDXkXJiw  Starbucks            80     2.5    $$            2   \n",
       "1  60agfQbky4cX8BEApyltIA  Starbucks            36     2.0     $            1   \n",
       "3  C0EKm9V9QI2R47QkRWA5aQ  Starbucks            44     3.0     $            1   \n",
       "4  OuNYQaqEJjkBHRdnC-4HOw  Starbucks            40     2.5    $$            2   \n",
       "5  mEMPhPK6dSgy5eXS-kYHLg  Starbucks            68     3.0    $$            2   \n",
       "\n",
       "    display_phone         address1 address2 address3      city state    zip  \\\n",
       "0  (718) 855-0856       67 Main St                    Brooklyn    NY  11201   \n",
       "1  (646) 699-9983     375 Pearl St                    New York    NY  10038   \n",
       "3  (929) 955-1841       99 Wall St                    New York    NY  10005   \n",
       "4  (212) 509-9709   100 William St                    New York    NY  10038   \n",
       "5  (718) 243-0455  134 Montague St                    Brooklyn    NY  11201   \n",
       "\n",
       "  country   latitude  longitude  \n",
       "0      US  40.702754 -73.990884  \n",
       "1      US  40.711020 -74.000910  \n",
       "3      US  40.704901 -74.007244  \n",
       "4      US  40.708413 -74.007387  \n",
       "5      US  40.694582 -73.993978  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check/reveview the merged DF\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb0c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies for handling the database\n",
    "from os import path, remove\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import Column, Integer, String, Float\n",
    "from sqlalchemy.orm import declarative_base, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9804c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the db path\n",
    "db_path = '../coffee_chains.sqlite'\n",
    "\n",
    "# Delete the existing database if it exists\n",
    "if path.exists(db_path):\n",
    "    remove(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b70fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the engine with the database and base\n",
    "engine = create_engine(f'sqlite:///{db_path}')\n",
    "Base = declarative_base()\n",
    "\n",
    "# Setup the table to be created if the database is being created\n",
    "class Shop(Base):\n",
    "    __tablename__ = 'shops'    \n",
    "    id = Column(Integer, primary_key = True)\n",
    "    name = Column(String(200))\n",
    "    review_count = Column(Integer)\n",
    "    rating = Column(Float)\n",
    "    price = Column(String(10))\n",
    "    price_point = Column(Integer)\n",
    "    display_phone = Column(String(50))\n",
    "    address1 = Column(String(200))\n",
    "    address2 = Column(String(200))\n",
    "    address3 = Column(String(200))\n",
    "    city = Column(String(200))\n",
    "    state = Column(String(100))\n",
    "    zip = Column(String(50))\n",
    "    country = Column(String(100))\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "# Create the SQLite database and the table\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7a8bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['shops'])\n"
     ]
    }
   ],
   "source": [
    "# Check the table to see if it has been created\n",
    "print(Base.metadata.tables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ba2eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the DF to the shop table created\n",
    "df_merged.to_sql(name = 'shop',con = engine, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af711d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.CursorResult at 0x133f84bc3d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check to see if things got appended correctly\n",
    "session = Session(bind = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0007e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qcnoyytlFIuqlcjDXkXJiw', 'Starbucks', 80, 2.5, '$$', 2, '(718) 855-0856', '67 Main St', '', '', 'Brooklyn', 'NY', '11201', 'US', 40.70275444, -73.99088374)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(text('SELECT * FROM shop')).fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42779939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close out of the session and engine\n",
    "session.close()\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43a72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
